{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from numpy import random as rand"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lecture 0: Hypothesis Testing and Bayesian Inference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hypothesis Testing\n",
    "\n",
    "Let's suppose that we want to study the heights of women in an auditorium in the United States. As each attendee walks through the door, if they are a woman, we measure their height in feet and log it into a table. We end up getting 100 records, stored in the variable `height_data`.\n",
    "\n",
    "We wish to know if the women in this hall are unusually different in height from the average. Suppose we know that the United States *average for women's height is 5.3 ft*. How do we go about answering this question?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "height_data = np.array([ 5.4463325 ,  5.62446452,  5.53362717,  5.41840439,  5.54579968,\n",
    "        5.51183131,  5.53218392,  5.4654995 ,  5.4901124 ,  5.52057526,\n",
    "        5.30584564,  5.42439939,  5.55457067,  5.54465133,  5.44327523,\n",
    "        5.62037858,  5.52781788,  5.50287702,  5.41490811,  5.48793098,\n",
    "        5.46397703,  5.50804981,  5.66262185,  5.47081631,  5.4647536 ,\n",
    "        5.49797981,  5.39970744,  5.57966582,  5.51613665,  5.45592252,\n",
    "        5.47052281,  5.49876025,  5.46882465,  5.44975778,  5.44192282,\n",
    "        5.47944829,  5.58792179,  5.53632426,  5.52901173,  5.46543961,\n",
    "        5.56631818,  5.52534841,  5.41354291,  5.51852838,  5.46921556,\n",
    "        5.48675372,  5.44138706,  5.45842293,  5.55172381,  5.57867342,\n",
    "        5.48032121,  5.51238043,  5.54710415,  5.45894236,  5.56520315,\n",
    "        5.55374592,  5.5128164 ,  5.41981803,  5.43610157,  5.51565714,\n",
    "        5.50572584,  5.38422721,  5.58470447,  5.34516383,  5.53209321,\n",
    "        5.53490615,  5.4891404 ,  5.49261317,  5.45588945,  5.41994864,\n",
    "        5.44053361,  5.4413407 ,  5.46232118,  5.53635502,  5.38358796,\n",
    "        5.4886594 ,  5.46582025,  5.61535408,  5.49692262,  5.35964358,\n",
    "        5.47217035,  5.3502072 ,  5.43681851,  5.55927506,  5.45716359,\n",
    "        5.68261663,  5.39582853,  5.55418574,  5.4420215 ,  5.55767895,\n",
    "        5.33742007,  5.55390882,  5.36797114,  5.49809592,  5.52609733,\n",
    "        5.47785981,  5.47016941,  5.49406023,  5.51270129,  5.5315854 ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What Can We Do?\n",
    "\n",
    "Clearly we cannot use pure logic to figure this out and there isn't an exact yes or no answer to this question. But we can wonder whether the chances of finding a group of 100 women with at least this particular average height is 'small' **assuming that our sample actually follows the national trend and has a true mean of 5.3 ft**.\n",
    "\n",
    "This method of inquiry is similar to the idea of proof by contradiction. If we thought our auditorium was unusual, we would assume that our sample isn't particularly special with respect to height, and aim to show a contradiction. The probability of such an event being 'small' is analogous to our hypothetical contradiction.\n",
    "\n",
    "Here, 'small' will mean that such chances are below a predefined cut-off value $\\alpha$, which we call the *level of significance* of the test. We will explore this more later.\n",
    "\n",
    "To answer our question, we do the following:\n",
    "1. We make some hypothesis\n",
    "\n",
    "    + $H_0$: Our sample mean is the same as the national average and any deviations are produced by random processes alone\n",
    "    \n",
    "    + $H_a$: Our sample mean is different from the national average and deviations are not SOLELY produced by random processes\n",
    "\n",
    "2. We choose a reasonable level of significance, $\\alpha$, upon which we will decide whether or not to reject $H_0$\n",
    "\n",
    "2. We will assume that $H_0$ is true and compute the probability of getting a result at least as extreme as our sample mean. This probability is denoted $p$ and called the **p-value** of the test\n",
    "\n",
    "3. We compare the p-value to our cut-off, $\\alpha$\n",
    "\n",
    "    + If $p < \\alpha$, then we reject $H_0$ for this trial with significance level $\\alpha$\n",
    "    \n",
    "    + If $p \\geq \\alpha$, we cannot reject $H_0$ for this trial with significance level $\\alpha$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's Do Some Math: The One Sample T-Test\n",
    "\n",
    "Let us consider our $n$ points of data as a realization of $n$ independent, identically distributed random variables (i.i.d's) \n",
    "\n",
    "$$x_1, x_2, \\dots , x_{n}$$\n",
    "\n",
    "Since $x_i$ represents heights, and height is produced by a multitude of independent random effects in the same population, we know by the Central Limit Theorem that each of these variables can be thought of as normally distributed, all with the same mean and variance\n",
    "\n",
    "$$x_i \\sim \\mathcal{N}(\\mu, \\sigma)$$\n",
    "\n",
    "From this, we construct a new random variable $\\bar{x}$, whose realizations represent sample means\n",
    "\n",
    "$$\\bar{x} = \\sum_{i=1}^{n} \\frac{x_i}{n}$$\n",
    "\n",
    "The CLT tells us that since $x_i \\sim \\mathcal{N}(\\mu, \\sigma)$, \n",
    "$$\\bar{x} \\sim \\mathcal{N}\\left(\\mu, \\frac{\\sigma}{\\sqrt{n}}\\right)$$\n",
    "\n",
    "We now construct another random variable, $Z$, which gives us information about how different $\\bar{x}$ is from $\\mu$\n",
    "\n",
    "$$Z = \\frac{\\bar{x} - \\mu}{\\frac{\\sigma}{\\sqrt{n}}} = \\sqrt{n} \\cdot \\frac{(\\bar{x} - \\mu)}{\\sigma} = \\frac{\\bar{x} - \\mu}{\\sqrt{\\frac{\\sigma^2}{n}}}$$\n",
    "\n",
    "W.S Gosset, writing under the pseudonym 'Student', proved that $Z \\sim \\mathcal{N}$ **only when** $x_i$ are normally distributed and both $\\mu$ and $\\sigma$ are known. If, instead, we knew only $\\mu$ and estimated $\\sigma$ by the sample standard deviation $s$, then our estimated z-score\n",
    "\n",
    "$$ T = \\sqrt{n} \\cdot \\frac{(\\bar{x} - \\mu)}{s} = \\frac{\\bar{x} - \\mu}{\\sqrt{\\frac{s^2}{n}}} $$\n",
    "\n",
    "follows a **t-distribution** rather than a normal distribution. The t-distribution is symmetric, bell-shaped, and approximates the normal distribution increasingly well with a greater number of trials. What's more, the t-distribution does not depend on either $\\mu$ or $\\sigma$, but only on a data-dependent term called the *degrees of freedom*, DF!\n",
    "\n",
    "Note that to calculate the same standard deviation $s$, you must use Bessel's correction, which scales the uncorrected sample variance by $\\frac{n}{n-1}$. The '1' in $n-1$, relates to the fact that we wish to estimate one parameter, $\\mu$ using our sample data.\n",
    "\n",
    "We define $DF = n - a$, where $n$ is the number of samples ($n = 100$) and $a$ is the number of parameters we aim to estimate from the sample ($a = 1$, namely the mean $\\mu$). In our case, $DF = 99$, $\\bar{x} = \\sum_{i=1}^{100} \\frac{x_i}{100}$, and $ T = \\sqrt{100} \\cdot \\frac{(\\bar{x} - \\mu)}{s} $"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x13e4ed0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from scipy.stats import t, norm\n",
    "import matplotlib.pyplot as plt\n",
    "fig, ax = plt.subplots(1, 1)\n",
    "df = 99\n",
    "df2 = 5\n",
    "x = np.linspace(t.ppf(0.01, df),\n",
    "              t.ppf(0.99, df), 100)\n",
    "ax.plot(x, t.pdf(x, df),\n",
    "        'b-', lw=2, alpha=0.4, label='t pdf')\n",
    "\n",
    "x2 = np.linspace(t.ppf(0.01, df2),\n",
    "              t.ppf(0.99, df2), 100)\n",
    "ax.plot(x2, t.pdf(x, df2),\n",
    "         'r-', lw=2, alpha=0.4, label='t pdf')\n",
    "plt.title('t_5 vs t_99')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's See It In Action!\n",
    "\n",
    "Now, noting that $T \\sim t_{99}$, we can translate our above decision-making process into math:\n",
    "\n",
    "1. Let $\\mu_0$ be the known average height of women in the US, and $\\mu$ be the expected sample mean\n",
    "    + $H_0$: $\\mu = \\mu_0$\n",
    "    + $H_a$: $\\mu \\neq \\mu_0$\n",
    "\n",
    "2. Let us choose $\\alpha = 0.05$, or 5%\n",
    "    \n",
    "2. Assume $H_0$ is true (so $\\mu$ in the above calculations can be replaced by the population mean, 5.3 ft). Let $T_x$ be the value of $T$ that we get from our data. We calculate\n",
    "$$ p = P(\\ |T| \\geq T_x\\ \\mid \\ H_0) $$\n",
    "\n",
    "4. If $p < \\alpha$, we reject $H_0$ for this trial (and thus accepting $H_a$). Otherwise, we decide not to reject (accepting $H_0$)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Calculations\n",
    "We will calculate the p-value 'manually', and then confirm it using `scipy.stats`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "T_x = 27.771597524482274, p = 1.5848015021140444e-48\n",
      "Reject H_0\n"
     ]
    }
   ],
   "source": [
    "from numpy import sqrt, mean, std, var\n",
    "from scipy.stats import t\n",
    "\n",
    "#Step 1\n",
    "mu_0 = 5.3 #Population mean\n",
    "mu = mu_0 #Assuming H_0\n",
    "\n",
    "#Step 2\n",
    "alpha = 0.05 #Choosing significance level\n",
    "\n",
    "#Step 3\n",
    "n = 100 #Number of trials\n",
    "a = 1 #Number of parameters\n",
    "df = n - a #Degrees of freedom\n",
    "\n",
    "x_bar = mean(height_data) #Sample mean\n",
    "s = std(height_data, ddof=a) #Sample Standard Deviation with 'a' parameters\n",
    "T_x = sqrt(n)*(x_bar - mu)/s\n",
    "p = 2*t.sf(abs(T_x),df) #sf is defined as 1 - cdf of the t-distribution. Doubling gives the two-tailed p-value\n",
    "\n",
    "#Step 4\n",
    "print (f'T_x = {T_x}, p = {p}')\n",
    "if p <= alpha:\n",
    "    print('Reject H_0')\n",
    "else:\n",
    "    print('Do not reject H_0')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "T_x = 27.771597524482274, p = 1.5848015021140444e-48\n",
      "Reject H_0\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import ttest_1samp\n",
    "\n",
    "T_x, p = ttest_1samp(height_data,mu_0) #scipy.stats 1 sample t-test\n",
    "\n",
    "print(f'T_x = {T_x}, p = {p_val}')\n",
    "if p <= alpha:\n",
    "    print('Reject H_0')\n",
    "else:\n",
    "    print('Do not reject H_0')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How Can We Screw Up? Precision and Recall\n",
    "\n",
    "There are two ways this test can lead us wrong:\n",
    "1. We end up rejecting $H_0$ when it was actually true (called a Type I error)\n",
    "2. We end up not rejecting $H_0$ when it was actually false (called a Type II error)\n",
    "\n",
    "If we observe Type I errors, we can see that this depends only on what we decided our cut-off value was, since that is what determined rejection when $H_0$ was true. *Hence the level of significance, $\\alpha$ is also the probability of a Type I error*\n",
    "\n",
    "We similarly denote the probability of a Type II error by $\\beta$.\n",
    "\n",
    "#### Precision and Recall\n",
    "\n",
    "Given this information, we can make a table of all possible outcomes of the test\n",
    "\n",
    "|  |   | $H_0$ is False  |   | $H_0$ is True  |\n",
    "|---|---|---|---|---|\n",
    "| Rejected $H_0$  |   | True Positives  |   | Type I Errors  |\n",
    "|   |   |   |   |   |\n",
    "| Did Not Reject $H_0$  |   | Type II Errors  |   | True Negatives  |\n",
    "\n",
    "We define the ** precision ** of our test to be $$\\text{precision} = \\frac{\\text{True Positives}}{\\text{True Positives} + \\text{Type I Errors}} $$ The precision is a measure of how likely it is that $H_0$ is false, given we rejected it. It denotes predictive power of the test.\n",
    "\n",
    "We define the ** recall ** of our test to be $$\\text{recall} = \\frac{\\text{True Positives}}{\\text{True Positives} + \\text{Type II Errors}} $$ The recall is a measure of how likely it is that we reject $H_0$ given that it is false. It denotes the probability of detecting false hypotheses.\n",
    "\n",
    "Choosing $\\alpha$ and $\\beta$ in your experiment affects all four of these quanitites, and so it should be done carefully to minimize detrimental errors, and maximize strength of the test in your given scenario."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What Did We Assume Again?\n",
    "\n",
    "Looking back at our analysis, we can see that we made a couple assumptions about our data before using the T-Test. It is necessary that the following conditions are verified before a T-Test can be used, since otherwise the mathematics simply won't hold:\n",
    "\n",
    "#### Conditions\n",
    "1. The data must be independent (random samples)\n",
    "2. The populations that the data come from must be approximately normally distributed (This was used in the proof of Gosset). For example, $x_i \\sim t_{DF}$ satisfies this condition\n",
    "3. The variances $\\sigma_i^2$ must be equal\n",
    "4. The data must be continuous (T-Tests do not apply to discrete random variables)\n",
    "5. The data must be commensurable. This means that there must be a common metric with which all the data can be measured, such as degrees Celsius, degrees Fahrenheit, meters, gallons, etc. **In particular, a T-Test cannot be used on a collection of probabilities!**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What Does The P-Value Mean?\n",
    "\n",
    "Let's recall from earlier that the p-value is the probability that one obtains a characteristic number (like $T$) at least as extreme as the one our data gives us. What do we mean by 'at least as extreme'? In our example, 'more extreme' is interpretted as 'has a T-score farther from 0 than $T_x$'. This was represented mathematically as the two-tailed probability\n",
    "$$p = P(\\ |T| \\geq T_x\\ \\mid \\ H_0) = P(\\ T \\geq T_x\\ OR\\  T \\leq -T_x\\ \\mid \\ H_0) $$\n",
    "\n",
    "Depending on the circumstance, you may elect to use the one-tailed probabilities\n",
    "$$p = P(\\ T \\geq T_x\\ \\mid \\ H_0) $$ or $$p = P(\\ T \\leq -T_x\\ \\mid \\ H_0) $$ if you were test was only considering whether or not the women in the auditorium were significantly taller, or shorter respectively than the national average.\n",
    "\n",
    "One thing to keep in mind is that the p-value is always defined **under the assumption that $H_0$ is true!** The p-value is conditional on this assumption, and this leads us to the following:\n",
    "\n",
    "#### What DOESN'T The P-Value Mean?\n",
    "\n",
    "1. **The p-value is NOT the probability that $H_0$ is true.** It relies on the assumption that $H_0$ is true to even exist!\n",
    "2. **The p-value is NOT the probability that the observed effects were produced by random chance alone.** Going back to read our definition of $H_0$, this would be equivalent to Misconception 1.\n",
    "3. **A p-value of less than 0.05 is NOT necessarily significant.** The 0.05 level of significant is arbitrarily chosen. A test is more confident of the decision to reject the null for smaller $\\alpha$, however this raises the chance that you actually keep a false null hypothesis.\n",
    "4. **A small p-value does NOT mean the property being tested is important.** Unimportant effects can return small p-values precisely because they may be uncommonly directly observed.\n",
    "\n",
    "#### Takeaway\n",
    "\n",
    "* The p-value and choice of $\\alpha$ form a criterion by which the researcher can make a decision about their hypotheses. They do not in any way refer to the probabilities of the hypotheses themselves. *By repeating experiments many times and reasonably lowering $\\alpha$, the researcher aims to make a metaphorical sieve through which hypotheses without enough evidence supporting them are rejected, and the remaining are tested once again.* A single p-value is dependent on the current data, and shouldn't be used as a measure of truth, but rather a measure of the strength of evidence."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Paired and Two Sample T-Tests\n",
    "\n",
    "Depending on your data and the kind of hypothesis you wish to make, there are other types of T-Tests which you can employ. The proceedure will be almost exactly as above, except we may have a different definition for the characteristic random variable $T$. All the following tests follow the t-distribution with the specified DF value:\n",
    "\n",
    "#### Paired T-Test\n",
    "\n",
    "This is used when your data comes in connected sample pairs, $(x_1,y_1), (x_2,y_2), \\dots, (x_n,y_n)$ where ever pair $(x_i,y_i)$ is independent of the others. We are interested in the differences in treatment for each subject $$d_i = y_i - x_i$$\n",
    "\n",
    "We wish to test whether or not a given treatment had any effect, $$H_0:\\ \\mu_d = 0$$ and so we apply the One Sample T-Test to the sequence of differences, $d_1, d_2, \\dots, d_n$ with $DF = n-1$, since $x_i, y_i$ are **not** independent of one another. We make the assumption that $d_i$ is approximately normally distributed, satisfying the conditions of the One Sample T-Test. One strength of this is that the original variables $x_i,\\ y_i$ can be very far from normally distributed, so long as their difference is normal. \n",
    "\n",
    "#### Two Sample T-Tests\n",
    "\n",
    "Suppose you have two independent samples from normally distributed populations of equal variance (labeled by 1 and 2). Further suppose that you have equal sample sizes $n$, and you wish to test the hypothesis $$H_0:\\ \\mu_1 = \\mu_2 $$\n",
    "\n",
    "Then we consider the new random variable $$\\bar{t} = \\frac{|\\bar{x_1} - \\bar{x_2}|}{\\sqrt{\\frac{s_1^2 + s_2^2}{n}}} $$ where $\\bar{x_i}$ is the sample mean, and $s_i^2$ is the sample variance. Since the samples are independent, we have $DF = (n-1) + (n-1) = 2n-2$, and so $$\\bar{t} \\sim t_{2n-2}$$\n",
    "\n",
    "If the two sample sizes are not too small and not too different, this test is very robust against departures from normal distributions, making this a very versatile test."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bayesian Posterior Inference\n",
    "\n",
    "In the previous section, we made note that p-values tell you the probability you saw your data given a null hypothesis. Suppose we actually wanted to know the probability of that hypothesis instead, given we saw the data we got. How can we do this?\n",
    "\n",
    "### Bayes' Formula\n",
    "\n",
    "Bayes' Formula gives you a way of converting between these two types of probabilities! Suppose $X = (x_1,\\dots, x_n)$ where the $x_i$'s are i.i.ds but with unknown distribution. Let $\\theta$ be the parameter of the data's distribution. Note that $\\theta$ parameterizes hypotheses about the distribution of $x_i$. Then $$P(\\ \\theta\\ \\mid\\ X\\ ) = \\frac{P(\\ X\\ \\mid\\ \\theta\\ )\\cdot P(\\ \\theta\\ )}{P(\\ X\\ )} = \\frac{P(\\ X\\ \\mid\\ \\theta\\ )\\cdot P(\\ \\theta\\ )}{\\int P(\\ X\\ \\mid\\ \\theta\\ )\\cdot P(\\ \\theta\\ ) d\\theta} $$\n",
    "\n",
    "One particular feature of this equation is the existence of $P(\\theta)$ in the numerator. This is the **prior probability** of $\\theta$, since it represents the 'belief' in the truth of $\\theta$ before having seen the data $X$. The term $P(\\ X\\ \\mid\\ \\theta\\ )$ is known as the **likelihood function**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Some Difficulties\n",
    "\n",
    "Attempting to use Bayes' Formula for our inferences provides us with some challenges. \n",
    "\n",
    "* How do we decide on what prior to choose for $\\theta$, or for that matter, does there even exist a prior which will stabilize at the true distribution after many updates? An answer to this question comes in the form of **De Finetti's Representation Theorem**, which while very interesting, is outside the scope of this lecture.\n",
    "\n",
    "* The denominator involves an integral $\\int P(\\ X\\ \\mid\\ \\theta\\ )\\cdot P(\\ \\theta\\ ) d\\theta$ over all hypotheses. This integral is often very difficult to evaluate. Is there any simplifications we can make that gets us around this? Is there a way we can still make inferences without having to evaluate this integral at all?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conjugate Priors\n",
    "\n",
    "To answer part of the second question, if we know the distribution of the likelihood function, and it happens to be in a specific known family of distributions, we can make a choice of prior which gives Bayes' Formula a nice closed form.\n",
    "\n",
    "Let's take the example of flipping a potentially biased coin."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Suppose we wish to know whether a coin in biased. We say the probability of getting heads is $0 < p < 1$. Then the distribution of the random variable $h$ which is the number of heads in $n$ trials is given by the binomial distribution $$P(s) = {n \\choose s}p^s (1-p)^{n-s}$$\n",
    "\n",
    "This is the likelihood of getting $h$ heads from n trials under the hypothesis that $p$ is given. The choice of conjugate prior for this likelihood function is $$P(p) = Beta(a,b) = \\frac{p^{a-1}(1-p)^{b-1}}{B(a,b)}$$\n",
    "\n",
    "$$B(x,y) = \\int_0^1 t^{x-1}(1-t)^{y-1}dt $$\n",
    "\n",
    "where $B(x,y)$ is the Beta function with $Re\\ x, Re\\ y > 0$, and $a$ and $b$ can be chosen freely initially to match your existing beliefs. We will choose $a = b = 3$, which is a prior concentrated around 0.5, which demonstrates a belief that the coin is fair."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Having run a test with 6 flips, suppose I find that my sequence of flips is $X = HHHHHT$. Appplying Bayes' Formula, we get\n",
    "$$P(X\\ \\mid\\ p) = {6 \\choose 5}p^5 (1-p)^{1} $$\n",
    "$$P(p) = Beta(3,3) = \\frac{p^{3-1}(1-p)^{3-1}}{B(3,3)} = \\frac{p^{3-1}(1-p)^{3-1}}{\\int_0^1 t^{3-1}(1-t)^{3-1}dt}$$\n",
    "\n",
    "$$P(\\ p\\ \\mid\\ X\\ ) = {6 \\choose 5}p^5 (1-p)^{1} \\cdot \\frac{p^{2}(1-p)^{2}}{B(3,3)}\\cdot \\frac{1}{\\int {6 \\choose 5}\\theta^5 (1-\\theta)^{1} \\cdot \\frac{p^{2}(1-\\theta)^{2}}{B(3,3)} d\\theta} = \\frac{{6 \\choose 5}p^7 (1-p)^{3}}{\\int {6 \\choose 5}\\theta^7 (1-\\theta)^{3} d\\theta} = Beta(8,4)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we can see we have updated our original prior, $Beta(3,3)$ to $Beta(7,3)$ which a more skewed distribution. So we are led to believe that the coin may in fact be biased."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Posterior Sampling\n",
    "\n",
    "If you aren't able to use a conjugate prior, there is another way you can make inferences about the distribution of the posterior without having to compute the integral, however, it requires that you restrict yourself to look at a characteristic value of the distribution, like the mean or variance\n",
    "\n",
    "See *http://twiecki.github.io/blog/2015/11/10/mcmc-sampling/* for a well layed-out example of how this is accomplished"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
